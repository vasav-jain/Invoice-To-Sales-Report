{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "For the sake of runtime, there are only 15 invoices in the data/raw folder. To add more invoices, you can find and move more invoices from the data/temp folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source venv/bin/activate'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create virtual environment for Python 3.10.14 -- Run this script in the terminal\n",
    "\"python3.10 -m venv venv\"\n",
    "\"source venv/bin/activate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy==1.26.4 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas==1.5.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.99.9)\n",
      "Requirement already satisfied: python-dotenv==1.1.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: pdfplumber==0.6.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: pytesseract==0.3.8 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.3.8)\n",
      "Requirement already satisfied: matplotlib==3.6.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.6.3)\n",
      "Requirement already satisfied: pdf2image==1.16.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.16.3)\n",
      "Requirement already satisfied: Pillow==9.1.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (9.1.0)\n",
      "Requirement already satisfied: plotly==5.3.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.3.0)\n",
      "Collecting reportlab (from -r requirements.txt (line 11))\n",
      "  Using cached reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: pdfminer.six==20220319 in ./venv/lib/python3.10/site-packages (from pdfplumber==0.6.2->-r requirements.txt (line 5)) (20220319)\n",
      "Requirement already satisfied: Wand>=0.6.7 in ./venv/lib/python3.10/site-packages (from pdfplumber==0.6.2->-r requirements.txt (line 5)) (0.6.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/lib/python3.10/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 7)) (3.2.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.10/site-packages (from plotly==5.3.0->-r requirements.txt (line 10)) (9.1.2)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.10/site-packages (from plotly==5.3.0->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: cryptography in ./venv/lib/python3.10/site-packages (from pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 5)) (45.0.6)\n",
      "Requirement already satisfied: chardet in ./venv/lib/python3.10/site-packages (from pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 3)) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 3)) (0.4.1)\n",
      "Collecting charset-normalizer (from reportlab->-r requirements.txt (line 11))\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in ./venv/lib/python3.10/site-packages (from cryptography->pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.10/site-packages (from cffi>=1.14->cryptography->pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 5)) (2.22)\n",
      "Using cached reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Installing collected packages: charset-normalizer, reportlab\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [reportlab]/2\u001b[0m [reportlab]\n",
      "\u001b[1A\u001b[2KSuccessfully installed charset-normalizer-3.4.3 reportlab-4.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install Dependncies -- Run this script in the terminal\n",
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OPENAI_API_KEY=your_openai_api_key_here'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure OpenAI API Key -- Create a .env file in the root directory of your project with the following content\n",
    "\"OPENAI_API_KEY=your_openai_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Paths\n",
    "RAW_DATA_FOLDER = \"data/raw\"\n",
    "REPORT_OUTPUT_PATH = \"output/Sales_Intelligence_Report.pdf\"\n",
    "PARSED_OUTPUT_PATH = \"output/parsed_invoices.csv\"\n",
    "AGGREGATED_OUTPUT_PATH = \"output/aggregations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1: Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting PDF to Image\n",
    "\n",
    "def pdf_to_base64_image(pdf_path):\n",
    "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
    "    if not images:\n",
    "        return None\n",
    "    buffered = BytesIO()\n",
    "    images[0].save(buffered, format=\"PNG\")\n",
    "    img_bytes = buffered.getvalue()\n",
    "    return base64.b64encode(img_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean JSON string\n",
    "\n",
    "def clean_json_string(raw_str):\n",
    "    return re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw_str.strip(), flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Details from PDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        b64_image = pdf_to_base64_image(pdf_path)\n",
    "        if not b64_image:\n",
    "            print(f\"‚ùå Failed to convert PDF to image: {pdf_path}\")\n",
    "            return None\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": (\n",
    "                                \"Extract the following structured fields from this invoice image: \"\n",
    "                                \"Invoice ID, Date, Customer Name, Country to Ship To, Category, Rate, Quantity, Amount. \"\n",
    "                                \"If no field is missing, return the result as a JSON object with each field as a key\"\n",
    "                                \"If any field is missing, just return one word: Invalid\"\n",
    "                            )\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{b64_image}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1200\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"Invalid\" in result or \"invalid\" in result:\n",
    "            print(f\"Data missing\")\n",
    "            return None\n",
    "        try:\n",
    "            cleaned = clean_json_string(result)\n",
    "            json_result = json.loads(cleaned)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid format\")\n",
    "            return None\n",
    "\n",
    "        return json_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"TPM Limit Reached\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing: invoice_Aaron Hawkins_47905.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_40100.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_40101.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_36652.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_36651.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_4820.pdf\n",
      "üìÑ Processing: invoice_Aaron Bergman_39519.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_6817.pdf\n",
      "üìÑ Processing: invoice_Aaron Bergman_36260.pdf\n",
      "Data missing\n",
      "üìÑ Processing: invoice_Aaron Hawkins_38461.pdf\n",
      "Data missing\n",
      "üìÑ Processing: invoice_Aaron Bergman_36259.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_37425.pdf\n",
      "üìÑ Processing: invoice_Aaron Bergman_36258.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_38460.pdf\n",
      "üìÑ Processing: invoice_Aaron Hawkins_49674.pdf\n",
      "Parsed 13/15 invoices into output/parsed_invoices.csv\n"
     ]
    }
   ],
   "source": [
    "# Parsing through all invoices\n",
    "\n",
    "parsed_data = []\n",
    "total = 0\n",
    "for filename in os.listdir(RAW_DATA_FOLDER):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        total += 1\n",
    "        pdf_path = os.path.join(RAW_DATA_FOLDER, filename)\n",
    "        print(f\"üìÑ Processing: {filename}\")\n",
    "        parsed = extract_text_from_pdf(pdf_path)\n",
    "        if parsed != None:\n",
    "            parsed_data.append(parsed)\n",
    "\n",
    "if parsed_data:\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    df.to_csv(PARSED_OUTPUT_PATH, index=False)\n",
    "    print(f\"Parsed {len(parsed_data)}/{total} invoices into {PARSED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"No valid invoices were parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: Sales Aggregater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(AGGREGATED_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Amount Column\n",
    "\n",
    "def clean_amount(value):\n",
    "    if isinstance(value, str):\n",
    "        return round(float(value.replace(\"$\", \"\").replace(\",\", \"\").strip()))\n",
    "    return round(float(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Columns\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df[\"Amount\"] = df[\"Amount\"].apply(clean_amount)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Data\n",
    "\n",
    "def aggregate_and_save(df, group_by, filename):\n",
    "    agg = df.groupby(group_by)[\"Amount\"].agg([\"sum\", \"count\"]).reset_index()\n",
    "    agg.columns = [group_by, \"Total Revenue\", \"Invoice Count\"]\n",
    "\n",
    "    if group_by == \"Month\":\n",
    "        agg = agg.sort_values(by=[group_by, \"Total Revenue\"], ascending=[True, False])\n",
    "    else:\n",
    "        agg = agg.sort_values(\"Total Revenue\", ascending=False)\n",
    "\n",
    "    agg.to_csv(os.path.join(AGGREGATED_OUTPUT_PATH, filename), index=False)\n",
    "    print(f\"Saved {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Monthly Trend\n",
    "\n",
    "def plot_monthly_trend(df):\n",
    "    monthly = df.groupby(\"Month\")[\"Amount\"].sum().sort_index()\n",
    "    monthly.plot(kind=\"line\", marker=\"o\", title=\"Monthly Revenue Trend\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Revenue\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(AGGREGATED_OUTPUT_PATH, \"monthly_trend.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved by_category.csv\n",
      "Saved by_country.csv\n",
      "Saved by_customer.csv\n",
      "Saved by_month.csv\n",
      "All aggregations and visualizations completed.\n"
     ]
    }
   ],
   "source": [
    "# Running the Aggregator\n",
    "\n",
    "if not os.path.exists(PARSED_OUTPUT_PATH):\n",
    "    print(f\"‚ùå File not found: {PARSED_OUTPUT_PATH}\")\n",
    "\n",
    "df = pd.read_csv(PARSED_OUTPUT_PATH)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "aggregate_and_save(df, \"Category\", \"by_category.csv\")\n",
    "aggregate_and_save(df, \"Country to Ship To\", \"by_country.csv\")\n",
    "aggregate_and_save(df, \"Customer Name\", \"by_customer.csv\")\n",
    "aggregate_and_save(df, \"Month\", \"by_month.csv\")\n",
    "\n",
    "plot_monthly_trend(df)\n",
    "\n",
    "print(\"All aggregations and visualizations completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 3: Recommender Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "category_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_category.csv\"))\n",
    "country_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_country.csv\"))\n",
    "monthly_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_month.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a prompt for OpenAI\n",
    "prompt = (\n",
    "    \"You are a sales analyst. Analyze this sales data and give 5 actionable, smart recommendations \"\n",
    "    \"to optimize revenue next quarter. Use evidence from data. Keep the output concise and executive-style.\\n\\n\"\n",
    "    f\"Top Categories:\\n{category_df.to_string(index=False)}\\n\\n\"\n",
    "    f\"Top Countries:\\n{country_df.to_string(index=False)}\\n\\n\"\n",
    "    f\"Monthly Trend:\\n{monthly_df.to_string(index=False)}\\n\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.5,\n",
    "    max_tokens=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To optimize revenue next quarter, consider the following recommendations based on the sales data:\n",
      "\n",
      "1. **Focus on High-Value Markets**: The Democratic Republic of the Congo and Guatemala generated significant revenue with single invoices. Develop targeted marketing strategies and explore partnerships to increase sales volume in these high-revenue markets.\n",
      "\n",
      "2. **Leverage High-Performing Categories**: Phones and Technology categories are top revenue generators. Expand product offerings, bundle deals, or introduce promotions in these categories to capitalize on their popularity.\n",
      "\n",
      "3. **Enhance U.S. Market Penetration**: Despite a higher invoice count, the U.S. market shows relatively low revenue. Implement targeted marketing campaigns, loyalty programs, or discounts to boost sales and increase average order values in this market.\n",
      "\n",
      "4. **Address Underperforming Categories**: Categories like Office Supplies and Art have minimal revenue. Consider revising product lines, offering bundled packages, or discontinuing low-demand items to focus resources on more profitable segments.\n",
      "\n",
      "5. **Optimize Seasonal Trends**: Revenue spikes in September and October suggest potential seasonal demand. Prepare for these peaks by ensuring adequate inventory, launching seasonal promotions, and enhancing marketing efforts during these months to maximize sales.\n",
      "\n",
      "These strategies aim to leverage high-revenue opportunities while addressing underperforming areas to drive overall revenue growth.\n"
     ]
    }
   ],
   "source": [
    "# Saving Insight Texts\n",
    "\n",
    "insights_text = response.choices[0].message.content.strip()\n",
    "print(insights_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 4: Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, Table, TableStyle\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "\n",
    "doc = SimpleDocTemplate(REPORT_OUTPUT_PATH, pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "elements = []\n",
    "\n",
    "elements.append(Paragraph(\"Sales Performance Report\", styles['Title']))\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeframe Calculator\n",
    "months_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_month.csv\"))\n",
    "start = months_df['Month'].min()\n",
    "end = months_df['Month'].max()\n",
    "elements.append(Paragraph(f\"Reporting Period: <b>{start}</b> to <b>{end}</b>\", styles['Normal']))\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Product Categories\n",
    "top_categories = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_category.csv\")).head(5)\n",
    "elements.append(Paragraph(\"Top 5 Product Categories by Revenue:\", styles['Heading2']))\n",
    "cat_table_data = [list(top_categories.columns)] + top_categories.values.tolist()\n",
    "cat_table = Table(cat_table_data, hAlign='LEFT')\n",
    "cat_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "]))\n",
    "elements.append(cat_table)\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Countries\n",
    "top_countries = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_country.csv\")).head(5)\n",
    "elements.append(Paragraph(\"Top 5 Countries by Revenue:\", styles['Heading2']))\n",
    "country_table_data = [list(top_countries.columns)] + top_countries.values.tolist()\n",
    "country_table = Table(country_table_data, hAlign='LEFT')\n",
    "country_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "]))\n",
    "elements.append(country_table)\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Trend\n",
    "elements.append(Paragraph(\"Monthly Revenue Trend:\", styles['Heading2']))\n",
    "trend_chart = os.path.join(AGGREGATED_OUTPUT_PATH, \"monthly_trend.png\")\n",
    "if os.path.exists(trend_chart):\n",
    "    elements.append(RLImage(trend_chart, width=400, height=250))\n",
    "    elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales report PDF created: output/Sales_Intelligence_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "# Recommendations\n",
    "elements.append(Paragraph(\"Recommendations\", styles['Heading2']))\n",
    "clean_insights = insights_text.replace(\"**\", \"\")\n",
    "for para in clean_insights.split(\"\\n\"):\n",
    "    if para.strip():\n",
    "        elements.append(Paragraph(para.strip(), styles['Normal']))\n",
    "        elements.append(Spacer(1, 6))\n",
    "\n",
    "doc.build(elements)\n",
    "print(f\"Sales report PDF created: {REPORT_OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
