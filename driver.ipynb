{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "For the sake of runtime, there are only 15 invoices in the data/raw folder. To add more invoices, you can find and move more invoices from the data/temp folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas==1.5.3 (from -r requirements.txt (line 1))\n",
      "  Downloading pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.50.2)\n",
      "Collecting python-dotenv==1.1.1 (from -r requirements.txt (line 3))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pdfplumber==0.6.2 (from -r requirements.txt (line 4))\n",
      "  Downloading pdfplumber-0.6.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting pytesseract==0.3.8 (from -r requirements.txt (line 5))\n",
      "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib==3.6.3 (from -r requirements.txt (line 6))\n",
      "  Downloading matplotlib-3.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pdf2image==1.16.3 (from -r requirements.txt (line 7))\n",
      "  Downloading pdf2image-1.16.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting Pillow==9.1.0 (from -r requirements.txt (line 8))\n",
      "  Downloading Pillow-9.1.0.tar.gz (49.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly==5.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading plotly-5.3.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2.0.2)\n",
      "Collecting pdfminer.six==20220319 (from pdfplumber==0.6.2->-r requirements.txt (line 4))\n",
      "  Downloading pdfminer.six-20220319-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Wand>=0.6.7 (from pdfplumber==0.6.2->-r requirements.txt (line 4))\n",
      "  Downloading Wand-0.6.13-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vasav/Library/Python/3.11/lib/python/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib==3.6.3->-r requirements.txt (line 6)) (3.1.4)\n",
      "Collecting tenacity>=6.2.0 (from plotly==5.3.0->-r requirements.txt (line 9))\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly==5.3.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: cryptography in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 4)) (43.0.1)\n",
      "Collecting chardet (from pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 4))\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.23.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography->pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography->pdfminer.six==20220319->pdfplumber==0.6.2->-r requirements.txt (line 4)) (2.22)\n",
      "Downloading pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pdfplumber-0.6.2-py3-none-any.whl (36 kB)\n",
      "Downloading matplotlib-3.6.3-cp311-cp311-macosx_11_0_arm64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
      "Downloading plotly-5.3.0-py2.py3-none-any.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading Wand-0.6.13-py2.py3-none-any.whl (143 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Building wheels for collected packages: pytesseract, Pillow\n",
      "  Building wheel for pytesseract (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14095 sha256=86c654bf96c29c6cc3ed7cf99217a801aec8cd2adbaa0dbec8182d9251e5ff63\n",
      "  Stored in directory: /Users/vasav/Library/Caches/pip/wheels/df/03/19/73d6ab496ab16b80e7ef09cf72ddd651100566f012ef712b41\n",
      "  Building wheel for Pillow (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pillow: filename=pillow-9.1.0-cp311-cp311-macosx_10_9_universal2.whl size=848902 sha256=a6a9b7034ed5d1c9adad6be919a1bbfe00abc58ef6e37277e97e386c2b5a6d97\n",
      "  Stored in directory: /Users/vasav/Library/Caches/pip/wheels/ec/43/38/04569b3f9c30520622da9d543523d956fdee4c30b6d5e651dd\n",
      "Successfully built pytesseract Pillow\n",
      "Installing collected packages: Wand, tenacity, python-dotenv, Pillow, chardet, pytesseract, plotly, pdf2image, pandas, matplotlib, pdfminer.six, pdfplumber\n",
      "\u001b[2K  Attempting uninstall: python-dotenv\n",
      "\u001b[2K    Found existing installation: python-dotenv 1.0.1\n",
      "\u001b[2K    Uninstalling python-dotenv-1.0.1:\n",
      "\u001b[2K      Successfully uninstalled python-dotenv-1.0.1\n",
      "\u001b[2K  Attempting uninstall: Pillow\n",
      "\u001b[2K    Found existing installation: pillow 10.4.0\n",
      "\u001b[2K    Uninstalling pillow-10.4.0:\n",
      "\u001b[2K      Successfully uninstalled pillow-10.4.0\n",
      "\u001b[2K  Attempting uninstall: pytesseract\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K    Found existing installation: pytesseract 0.3.10━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K    Uninstalling pytesseract-0.3.10:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K      Successfully uninstalled pytesseract-0.3.10━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K  Attempting uninstall: plotlym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K    Found existing installation: plotly 6.2.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K    Uninstalling plotly-6.2.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [chardet]\n",
      "\u001b[2K      Successfully uninstalled plotly-6.2.0[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: pdf2image[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K    Found existing installation: pdf2image 1.17.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K    Uninstalling pdf2image-1.17.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K      Successfully uninstalled pdf2image-1.17.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: pandas90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [plotly]\n",
      "\u001b[2K    Uninstalling pandas-2.2.2:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.2m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.9.2━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling matplotlib-3.9.2:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.9.2╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: pdfminer.six━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: pdfminer.six 20250506━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling pdfminer.six-20250506:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K      Successfully uninstalled pdfminer.six-20250506[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K  Attempting uninstall: pdfplumber━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K    Found existing installation: pdfplumber 0.11.7m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K    Uninstalling pdfplumber-0.11.7:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K      Successfully uninstalled pdfplumber-0.11.7[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [pdfminer.six]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [pdfplumber]m [pdfminer.six]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Pillow-9.1.0 Wand-0.6.13 chardet-5.2.0 matplotlib-3.6.3 pandas-1.5.3 pdf2image-1.16.3 pdfminer.six-20220319 pdfplumber-0.6.2 plotly-5.3.0 pytesseract-0.3.8 python-dotenv-1.1.1 tenacity-9.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install Dependncies -- Run the below code in terminal\n",
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OPENAI_API_KEY=your_openai_api_key_here'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure OpenAI API Key -- Create a .env file in the root directory of your project with the following content\n",
    "\"OPENAI_API_KEY=your_openai_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Paths\n",
    "RAW_DATA_FOLDER = \"data/raw\"\n",
    "REPORT_OUTPUT_PATH = \"output/Sales_Intelligence_Report.pdf\"\n",
    "PARSED_OUTPUT_PATH = \"output/parsed_invoices.csv\"\n",
    "AGGREGATED_OUTPUT_PATH = \"output/aggregations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1: Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "from io import BytesIO\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting PDF to Image\n",
    "\n",
    "def pdf_to_base64_image(pdf_path):\n",
    "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
    "    if not images:\n",
    "        return None\n",
    "    buffered = BytesIO()\n",
    "    images[0].save(buffered, format=\"PNG\")\n",
    "    img_bytes = buffered.getvalue()\n",
    "    return base64.b64encode(img_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean JSON string\n",
    "\n",
    "def clean_json_string(raw_str):\n",
    "    return re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw_str.strip(), flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Details from PDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        b64_image = pdf_to_base64_image(pdf_path)\n",
    "        if not b64_image:\n",
    "            print(f\"❌ Failed to convert PDF to image: {pdf_path}\")\n",
    "            return None\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": (\n",
    "                                \"Extract the following structured fields from this invoice image: \"\n",
    "                                \"Invoice ID, Date, Customer Name, Country to Ship To, Category, Rate, Quantity, Amount. \"\n",
    "                                \"If no field is missing, return the result as a JSON object with each field as a key\"\n",
    "                                \"If any field is missing, just return one word: Invalid\"\n",
    "                            )\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{b64_image}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1200\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"Invalid\" in result or \"invalid\" in result:\n",
    "            print(f\"Data missing\")\n",
    "            return None\n",
    "        try:\n",
    "            cleaned = clean_json_string(result)\n",
    "            json_result = json.loads(cleaned)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid format\")\n",
    "            return None\n",
    "\n",
    "        return json_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"TPM Limit Reached\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Processing: invoice_Aaron Hawkins_47905.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_40100.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_40101.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_36652.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_36651.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_4820.pdf\n",
      "📄 Processing: invoice_Aaron Bergman_39519.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_6817.pdf\n",
      "📄 Processing: invoice_Aaron Bergman_36260.pdf\n",
      "Data missing\n",
      "📄 Processing: invoice_Aaron Hawkins_38461.pdf\n",
      "Data missing\n",
      "📄 Processing: invoice_Aaron Bergman_36259.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_37425.pdf\n",
      "📄 Processing: invoice_Aaron Bergman_36258.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_38460.pdf\n",
      "📄 Processing: invoice_Aaron Hawkins_49674.pdf\n",
      "Parsed 13/15 invoices into output/parsed_invoices.csv\n"
     ]
    }
   ],
   "source": [
    "# Parsing through all invoices\n",
    "\n",
    "parsed_data = []\n",
    "total = 0\n",
    "for filename in os.listdir(RAW_DATA_FOLDER):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        total += 1\n",
    "        pdf_path = os.path.join(RAW_DATA_FOLDER, filename)\n",
    "        print(f\"📄 Processing: {filename}\")\n",
    "        parsed = extract_text_from_pdf(pdf_path)\n",
    "        if parsed != None:\n",
    "            parsed_data.append(parsed)\n",
    "\n",
    "if parsed_data:\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    df.to_csv(PARSED_OUTPUT_PATH, index=False)\n",
    "    print(f\"Parsed {len(parsed_data)}/{total} invoices into {PARSED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"No valid invoices were parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: Sales Aggregater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(AGGREGATED_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Amount Column\n",
    "\n",
    "def clean_amount(value):\n",
    "    if isinstance(value, str):\n",
    "        return round(float(value.replace(\"$\", \"\").replace(\",\", \"\").strip()))\n",
    "    return round(float(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Columns\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df[\"Amount\"] = df[\"Amount\"].apply(clean_amount)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Data\n",
    "\n",
    "def aggregate_and_save(df, group_by, filename):\n",
    "    agg = df.groupby(group_by)[\"Amount\"].agg([\"sum\", \"count\"]).reset_index()\n",
    "    agg.columns = [group_by, \"Total Revenue\", \"Invoice Count\"]\n",
    "\n",
    "    if group_by == \"Month\":\n",
    "        agg = agg.sort_values(by=[group_by, \"Total Revenue\"], ascending=[True, False])\n",
    "    else:\n",
    "        agg = agg.sort_values(\"Total Revenue\", ascending=False)\n",
    "\n",
    "    agg.to_csv(os.path.join(AGGREGATED_OUTPUT_PATH, filename), index=False)\n",
    "    print(f\"Saved {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Monthly Trend\n",
    "\n",
    "def plot_monthly_trend(df):\n",
    "    monthly = df.groupby(\"Month\")[\"Amount\"].sum().sort_index()\n",
    "    monthly.plot(kind=\"line\", marker=\"o\", title=\"Monthly Revenue Trend\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Revenue\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(AGGREGATED_OUTPUT_PATH, \"monthly_trend.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved by_category.csv\n",
      "Saved by_country.csv\n",
      "Saved by_customer.csv\n",
      "Saved by_month.csv\n",
      "All aggregations and visualizations completed.\n"
     ]
    }
   ],
   "source": [
    "# Running the Aggregator\n",
    "\n",
    "if not os.path.exists(PARSED_OUTPUT_PATH):\n",
    "    print(f\"❌ File not found: {PARSED_OUTPUT_PATH}\")\n",
    "\n",
    "df = pd.read_csv(PARSED_OUTPUT_PATH)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "aggregate_and_save(df, \"Category\", \"by_category.csv\")\n",
    "aggregate_and_save(df, \"Country to Ship To\", \"by_country.csv\")\n",
    "aggregate_and_save(df, \"Customer Name\", \"by_customer.csv\")\n",
    "aggregate_and_save(df, \"Month\", \"by_month.csv\")\n",
    "\n",
    "plot_monthly_trend(df)\n",
    "\n",
    "print(\"All aggregations and visualizations completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 3: Recommender Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "category_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_category.csv\"))\n",
    "country_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_country.csv\"))\n",
    "monthly_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_month.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a prompt for OpenAI\n",
    "prompt = (\n",
    "    \"You are a sales analyst. Analyze this sales data and give 5 actionable, smart recommendations \"\n",
    "    \"to optimize revenue next quarter. Use evidence from data. Keep the output concise and executive-style.\\n\\n\"\n",
    "    f\"Top Categories:\\n{category_df.to_string(index=False)}\\n\\n\"\n",
    "    f\"Top Countries:\\n{country_df.to_string(index=False)}\\n\\n\"\n",
    "    f\"Monthly Trend:\\n{monthly_df.to_string(index=False)}\\n\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.5,\n",
    "    max_tokens=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Focus on High-Value Categories and Countries**: Concentrate sales efforts on the Phones and Technology category, which accounts for the highest revenue. Target the Democratic Republic of the Congo and Guatemala, which have generated significant revenue from single invoices. Consider expanding product offerings or promotions in these regions to capitalize on existing demand.\n",
      "\n",
      "2. **Enhance U.S. Market Penetration**: Despite having the highest invoice count (9), the United States generates relatively low revenue. Implement targeted marketing campaigns and promotional offers to increase average transaction value and boost revenue from this market.\n",
      "\n",
      "3. **Seasonal and Monthly Sales Strategy**: Revenue peaks in September and October. Develop a marketing strategy to capitalize on this trend, such as launching back-to-school or pre-holiday promotions, to maximize sales during these high-revenue months.\n",
      "\n",
      "4. **Diversify Product Promotion**: The Furniture category, particularly Chairs, shows potential with moderate revenue from only three invoices. Develop bundled offers or discounts to increase sales volume and explore cross-selling opportunities with related categories like Office Supplies.\n",
      "\n",
      "5. **Monitor and Improve Low-Performing Categories**: Categories such as Art and Paper in Office Supplies have minimal revenue. Conduct market research to understand customer needs and adjust inventory or marketing strategies to either revitalize these categories or phase them out in favor of more profitable items.\n"
     ]
    }
   ],
   "source": [
    "# Saving Insight Texts\n",
    "\n",
    "insights_text = response.choices[0].message.content.strip()\n",
    "print(insights_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 4: Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, Table, TableStyle\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "\n",
    "doc = SimpleDocTemplate(REPORT_OUTPUT_PATH, pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "elements = []\n",
    "\n",
    "elements.append(Paragraph(\"Sales Performance Report\", styles['Title']))\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeframe Calculator\n",
    "months_df = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_month.csv\"))\n",
    "start = months_df['Month'].min()\n",
    "end = months_df['Month'].max()\n",
    "elements.append(Paragraph(f\"Reporting Period: <b>{start}</b> to <b>{end}</b>\", styles['Normal']))\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Product Categories\n",
    "top_categories = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_category.csv\")).head(5)\n",
    "elements.append(Paragraph(\"Top 5 Product Categories by Revenue:\", styles['Heading2']))\n",
    "cat_table_data = [list(top_categories.columns)] + top_categories.values.tolist()\n",
    "cat_table = Table(cat_table_data, hAlign='LEFT')\n",
    "cat_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "]))\n",
    "elements.append(cat_table)\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Countries\n",
    "top_countries = pd.read_csv(os.path.join(AGGREGATED_OUTPUT_PATH, \"by_country.csv\")).head(5)\n",
    "elements.append(Paragraph(\"Top 5 Countries by Revenue:\", styles['Heading2']))\n",
    "country_table_data = [list(top_countries.columns)] + top_countries.values.tolist()\n",
    "country_table = Table(country_table_data, hAlign='LEFT')\n",
    "country_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "]))\n",
    "elements.append(country_table)\n",
    "elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Trend\n",
    "elements.append(Paragraph(\"Monthly Revenue Trend:\", styles['Heading2']))\n",
    "trend_chart = os.path.join(AGGREGATED_OUTPUT_PATH, \"monthly_trend.png\")\n",
    "if os.path.exists(trend_chart):\n",
    "    elements.append(RLImage(trend_chart, width=400, height=250))\n",
    "    elements.append(Spacer(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales report PDF created: output/Sales_Intelligence_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "# Recommendations\n",
    "elements.append(Paragraph(\"Recommendations\", styles['Heading2']))\n",
    "clean_insights = insights_text.replace(\"**\", \"\")\n",
    "for para in clean_insights.split(\"\\n\"):\n",
    "    if para.strip():\n",
    "        elements.append(Paragraph(para.strip(), styles['Normal']))\n",
    "        elements.append(Spacer(1, 6))\n",
    "\n",
    "doc.build(elements)\n",
    "print(f\"Sales report PDF created: {REPORT_OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
